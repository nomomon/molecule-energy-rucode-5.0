{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !pip install ase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91jXtJw3HJV9"
   },
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9Fvgn69K1jqi",
    "outputId": "0f5031a4-a2cd-461e-c0c8-5fb35f25c7fb"
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !mv ./kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYdhmwa0x9Wj",
    "outputId": "15ba2cb7-f20b-431a-f774-bf768cad3748"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c molecular-energy-estimation-rucode\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('molecular-energy-estimation-rucode.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from ase.db import connect\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n",
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFMjdwhTl6Wi"
   },
   "source": [
    "# Visualizing Molecules\n",
    "\n",
    "Путем визуализации можно было посмотреть на молекулы и логическими рассуждениями понять когда между атомами есть связь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLY957AUr8rH"
   },
   "source": [
    "138365 molecules in the database\n",
    "\n",
    "```python\n",
    "i = 0\n",
    "for row in database.select():\n",
    "    i += 1\n",
    "print(i)\n",
    ">>> 138365\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KgScbQB6JbSJ"
   },
   "outputs": [],
   "source": [
    "train_db = connect(\"./data/train.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f9fXBGGYOBil"
   },
   "outputs": [],
   "source": [
    "def dist(p1, p2):\n",
    "    return np.sqrt(np.square(p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EXwrzxICLQAX",
    "outputId": "a04d08a5-f112-4281-8511-d86090544f8f"
   },
   "outputs": [],
   "source": [
    "def display_molecule(row, plt):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12, 8)\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "    # ax.grid(False)\n",
    "    \n",
    "    def init():\n",
    "        p = row.positions\n",
    "        s = row.symbols\n",
    "        n = row.numbers\n",
    "        \n",
    "        x = p[:, 0]\n",
    "        y = p[:, 1]\n",
    "        z = p[:, 2]\n",
    "\n",
    "        ax.scatter(x, y, z, \n",
    "            s = n*20,        # size\n",
    "            c = n,           # color\n",
    "            cmap = 'inferno'\n",
    "        )\n",
    "\n",
    "        for i in range(len(p)):\n",
    "            ax.text(x[i], y[i], z[i], \" \" + s[i])\n",
    "\n",
    "        for i in range(len(p)):\n",
    "            for j in range(i+1, len(p)):\n",
    "                # два условия которые подобрал для определения есть ли связь между атомами иди нет\n",
    "                # основано на моем базовом понимании химии\n",
    "                # если атомы на определенном расстоянии то между ними есть связь (covalent bond)\n",
    "                # у каждого атома ограниченное количество связей, проблемы были только у H-H связей\n",
    "                if s[i] == 'H' and s[j] == 'H':\n",
    "                    continue\n",
    "\n",
    "                if 3.5 < dist(p[i], p[j]) < 7:  # not sure if \"3.5 <\" is needed\n",
    "                    lx = [x[i], x[j]]           # it seems to work good without it\n",
    "                    ly = [y[i], y[j]]           # would be nice to read about the chem behind\n",
    "                    lz = [z[i], z[j]]\n",
    "\n",
    "                    ax.plot(lx, ly, lz, color='black')\n",
    "        return fig,\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        ax.view_init(elev=10., azim=i)\n",
    "        return fig,\n",
    "\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=360, interval=30, blit=True)\n",
    "    \n",
    "    plt.close()\n",
    "    return HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Красиво <img src=\"https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/240/apple/325/smiling-face-with-sunglasses_1f60e.png\" style=\"width:1.3em; margin:none; padding:none; display:inline;\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = train_db.get(100)\n",
    "\n",
    "display_molecule(molecule, plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guDvrsppToQX"
   },
   "source": [
    "# Median Baseline (не главное решение)\n",
    "\n",
    "Тут я даю медиану энергии в зависимости от атомов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSF24f6gTq2q",
    "outputId": "27994160-caed-4a05-86b0-65c4db238a92"
   },
   "outputs": [],
   "source": [
    "hash = {}\n",
    "\n",
    "for row in database.select():\n",
    "    atoms = row.symbols\n",
    "    for atom in atoms:\n",
    "        if atom not in hash:\n",
    "            hash[atom] = 1\n",
    "        else:\n",
    "            hash[atom] += 1\n",
    "\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvwAM2EhUB8H"
   },
   "outputs": [],
   "source": [
    "energy_per_atom = np.array(sorted(energy_per_atom))\n",
    "median_energy_per_atom = energy_per_atom[len(energy_per_atom) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOcsKwtXZBnn",
    "outputId": "91b1a3d3-13e7-4edc-ab77-a6d7468d98ce"
   },
   "outputs": [],
   "source": [
    "median_energy_per_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MvrK8-bY251",
    "outputId": "adc84095-9ab9-418d-be02-5b680e76fa50"
   },
   "outputs": [],
   "source": [
    "mean_energy_per_atom = energy_per_atom.mean()\n",
    "mean_energy_per_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8Wdqc03ZGhR"
   },
   "outputs": [],
   "source": [
    "test_database = connect('test.db')\n",
    "\n",
    "test_n_atoms = []\n",
    "\n",
    "for row in test_database.select():\n",
    "    test_n_atoms.append(row.natoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0inZ7XbLZbKH"
   },
   "outputs": [],
   "source": [
    "test_energy = np.array(test_n_atoms) * median_energy_per_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlPNxzdYUIuz"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv', index_col = 'id')\n",
    "sub['energy'] = test_energy\n",
    "\n",
    "sub.to_csv('molecule_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC89Bk8iPfym"
   },
   "source": [
    "# Linear Model Baseline (файнал сабмит)\n",
    "\n",
    "Идея простая, считаем количество каждой связи в молекуле и передаем эти числа нейронной сети. Это сработает так как энергия молекулы вычисляется путем суммы энергий в каждой связи. В данном решении различие между какие из связей двойные, а какие одинарные не учтено. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_db.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdges(n_atoms, symbols, positions):\n",
    "    edges = []\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        for j in range(i+1, n_atoms):\n",
    "            if symbols[i] == 'H' and symbols[j] == 'H':\n",
    "                continue\n",
    "            \n",
    "            d = dist(positions[i], positions[j])\n",
    "            if d < 7 and d > 3.5:\n",
    "                edges.append([i, j])\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RWKoXJgnPoKi"
   },
   "outputs": [],
   "source": [
    "def bondDistribution(row):\n",
    "    n_atoms = row.natoms\n",
    "    symbols = row.symbols\n",
    "    positions = row.positions\n",
    "    energy = row.data.get('energy')\n",
    "\n",
    "    edges = getEdges(n_atoms, symbols, positions)\n",
    "\n",
    "    hash = {}\n",
    "\n",
    "    for edge in edges:\n",
    "        bondName = ''.join(sorted([symbols[edge[0]], symbols[edge[1]]]))\n",
    "        if bondName in hash:\n",
    "            hash[bondName] += 1\n",
    "        else:\n",
    "            hash[bondName] = 1\n",
    "    \n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-si6Rg6GRD_U",
    "outputId": "1ff603ca-27b3-47a1-eb33-3f9f9401b601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC': 12, 'CH': 19, 'CS': 2, 'CN': 10, 'CO': 2, 'HN': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bondDistribution(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b-gH_gLj5y1Z"
   },
   "outputs": [],
   "source": [
    "def atomDistribution(row):\n",
    "    symbols = row.symbols\n",
    "\n",
    "    hash = {}\n",
    "    for symbol in symbols:\n",
    "        if symbol in hash:\n",
    "            hash[symbol] += 1\n",
    "        else:\n",
    "            hash[symbol] = 1\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k08hI3-06V8w",
    "outputId": "5175097f-ff43-4398-cbf1-471c75b904e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 17, 'S': 1, 'N': 4, 'O': 2, 'H': 20}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomDistribution(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "MAQGXREeSRJj",
    "outputId": "2f3a3ecc-d218-4fc9-efe8-3db623f8707f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>CC</th>\n",
       "      <th>CH</th>\n",
       "      <th>CN</th>\n",
       "      <th>CO</th>\n",
       "      <th>CS</th>\n",
       "      <th>H</th>\n",
       "      <th>HN</th>\n",
       "      <th>HO</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>S</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1426.322998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1426.318237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1426.317749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1426.314697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1388.484497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1388.467285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1388.455566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1388.466553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1233.530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C    CC    CH    CN   CO   CS     H   HN   HO    N    O    S  \\\n",
       "1  17.0  12.0  19.0  10.0  2.0  2.0  20.0  1.0  0.0  4.0  2.0  1.0   \n",
       "2  17.0  12.0  19.0  10.0  2.0  2.0  20.0  1.0  0.0  4.0  2.0  1.0   \n",
       "3  17.0  12.0  19.0  10.0  2.0  2.0  20.0  1.0  0.0  4.0  2.0  1.0   \n",
       "4  17.0  12.0  19.0  10.0  2.0  2.0  20.0  1.0  0.0  4.0  2.0  1.0   \n",
       "5  14.0   8.0  20.0  10.0  3.0  2.0  22.0  1.0  1.0  4.0  3.0  1.0   \n",
       "6  14.0   8.0  21.0  10.0  3.0  2.0  22.0  1.0  0.0  4.0  3.0  1.0   \n",
       "7  14.0   8.0  20.0  10.0  3.0  2.0  22.0  1.0  1.0  4.0  3.0  1.0   \n",
       "8  14.0   8.0  21.0  10.0  3.0  2.0  22.0  1.0  0.0  4.0  3.0  1.0   \n",
       "9  12.0   6.0  15.0  10.0  2.0  2.0  16.0  1.0  0.0  4.0  2.0  1.0   \n",
       "\n",
       "        energy  \n",
       "1 -1426.322998  \n",
       "2 -1426.318237  \n",
       "3 -1426.317749  \n",
       "4 -1426.314697  \n",
       "5 -1388.484497  \n",
       "6 -1388.467285  \n",
       "7 -1388.455566  \n",
       "8 -1388.466553  \n",
       "9 -1233.530884  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('./train_data.csv', index_col=0)\n",
    "df = pd.DataFrame()\n",
    "df['energy'] = 0\n",
    "\n",
    "for i in range(1, 138363 + 10): # 24 min + 13 min\n",
    "    try:\n",
    "        row = train_db.get(i)\n",
    "\n",
    "        bonds = bondDistribution(row)\n",
    "        for bond in bonds:\n",
    "            if bond not in df:\n",
    "                df[bond] = 0\n",
    "            df.loc[i, bond] = bonds[bond]\n",
    "        \n",
    "        atoms = atomDistribution(row)\n",
    "        for atom in atoms:\n",
    "            if atom not in df:\n",
    "                df[atom] = 0\n",
    "            df.loc[i, atom] = atoms[atom]\n",
    "\n",
    "        df.loc[i, 'energy'] = row.data.get('energy')[0]\n",
    "        \n",
    "    except:\n",
    "        print('stopped on', i)\n",
    "        break\n",
    "\n",
    "df = df.fillna(0)\n",
    "df = df.sort_index(axis=1)\n",
    "df.to_csv('train_data.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NN0JTNE_Y8_s"
   },
   "outputs": [],
   "source": [
    "xy = df.to_numpy()\n",
    "y = xy[:, -1]\n",
    "x = xy[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9oIJybKHZH0S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 12:35:52.492809: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-22 12:35:52.493350: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yNiC8fHHZ0NB",
    "outputId": "cd33c7b3-5f16-46bf-d43b-cb5b44141fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 12:35:55.235784: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-22 12:35:55.382626: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 529ms/step - loss: 1945767.7500 - mae: 1393.7250\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1945238.6250 - mae: 1393.5356\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1944711.7500 - mae: 1393.3469\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1944187.1250 - mae: 1393.1591\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1943664.6250 - mae: 1392.9720\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1943144.0000 - mae: 1392.7856\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1942626.2500 - mae: 1392.6001\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1942110.0000 - mae: 1392.4152\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1941596.2500 - mae: 1392.2311\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1941084.5000 - mae: 1392.0477\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1940574.6250 - mae: 1391.8650\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1940066.8750 - mae: 1391.6831\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1939561.3750 - mae: 1391.5017\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1939057.1250 - mae: 1391.3209\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1938556.8750 - mae: 1391.1417\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1938060.5000 - mae: 1390.9636\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1937565.3750 - mae: 1390.7860\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1937072.6250 - mae: 1390.6094\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1936583.7500 - mae: 1390.4341\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1936123.1250 - mae: 1390.2684\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1935673.7500 - mae: 1390.1071\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1935226.2500 - mae: 1389.9462\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1934780.2500 - mae: 1389.7858\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1934335.6250 - mae: 1389.6260\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1933892.0000 - mae: 1389.4664\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1933459.1250 - mae: 1389.3108\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1933051.7500 - mae: 1389.1639\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1932645.3750 - mae: 1389.0175\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1932240.0000 - mae: 1388.8716\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1931835.1250 - mae: 1388.7256\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1931430.6250 - mae: 1388.5798\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1931026.6250 - mae: 1388.4342\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1930622.2500 - mae: 1388.2887\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1930217.7500 - mae: 1388.1428\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1929813.3750 - mae: 1387.9971\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1929408.0000 - mae: 1387.8512\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1929002.2500 - mae: 1387.7048\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1928606.5000 - mae: 1387.5623\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1928221.3750 - mae: 1387.4235\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1927836.2500 - mae: 1387.2845\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1927463.6250 - mae: 1387.1501\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1927098.2500 - mae: 1387.0186\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1926733.6250 - mae: 1386.8871\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1926404.8750 - mae: 1386.7682\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1926076.0000 - mae: 1386.6493\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1925749.1250 - mae: 1386.5312\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1925422.2500 - mae: 1386.4135\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1925093.6250 - mae: 1386.2947\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1924762.6250 - mae: 1386.1754\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1924429.7500 - mae: 1386.0553\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1924095.1250 - mae: 1385.9346\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1923770.2500 - mae: 1385.8173\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1923443.7500 - mae: 1385.6995\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1923119.1250 - mae: 1385.5825\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1922792.5000 - mae: 1385.4648\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1922464.0000 - mae: 1385.3463\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1922141.3750 - mae: 1385.2301\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1921817.1250 - mae: 1385.1133\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1921491.3750 - mae: 1384.9958\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1921163.7500 - mae: 1384.8778\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1920839.6250 - mae: 1384.7609\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1920515.3750 - mae: 1384.6442\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1920188.8750 - mae: 1384.5262\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1919860.0000 - mae: 1384.4078\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1919528.5000 - mae: 1384.2883\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1919196.5000 - mae: 1384.1686\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1918862.5000 - mae: 1384.0483\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1918527.3750 - mae: 1383.9275\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1918193.7500 - mae: 1383.8074\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1917857.7500 - mae: 1383.6864\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1917518.6250 - mae: 1383.5642\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1917176.8750 - mae: 1383.4410\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1916832.5000 - mae: 1383.3169\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1916485.3750 - mae: 1383.1917\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1916135.1250 - mae: 1383.0653\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1915782.0000 - mae: 1382.9381\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1915426.2500 - mae: 1382.8099\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1915067.6250 - mae: 1382.6804\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1914705.7500 - mae: 1382.5502\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1914341.3750 - mae: 1382.4186\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1913973.7500 - mae: 1382.2860\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1913603.6250 - mae: 1382.1523\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1913230.2500 - mae: 1382.0177\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1912853.7500 - mae: 1381.8820\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1912474.6250 - mae: 1381.7451\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1912092.0000 - mae: 1381.6071\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1911706.6250 - mae: 1381.4680\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1911318.5000 - mae: 1381.3278\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1910927.1250 - mae: 1381.1865\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1910532.5000 - mae: 1381.0441\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1910134.6250 - mae: 1380.9005\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1909734.2500 - mae: 1380.7559\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1909330.5000 - mae: 1380.6100\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1908923.6250 - mae: 1380.4631\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1908513.6250 - mae: 1380.3151\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1908100.5000 - mae: 1380.1656\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1907684.0000 - mae: 1380.0153\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1907264.6250 - mae: 1379.8638\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1906841.7500 - mae: 1379.7109\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1906416.0000 - mae: 1379.5571\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1905986.8750 - mae: 1379.4020\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1905554.5000 - mae: 1379.2456\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1905118.6250 - mae: 1379.0881\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1904679.7500 - mae: 1378.9294\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1904237.7500 - mae: 1378.7695\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1903792.5000 - mae: 1378.6084\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1903343.6250 - mae: 1378.4462\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1902891.6250 - mae: 1378.2826\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1902436.0000 - mae: 1378.1178\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1901977.3750 - mae: 1377.9518\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1901515.3750 - mae: 1377.7845\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1901049.7500 - mae: 1377.6161\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1900580.8750 - mae: 1377.4464\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1900108.6250 - mae: 1377.2754\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1899633.1250 - mae: 1377.1033\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1899154.0000 - mae: 1376.9298\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1898676.8750 - mae: 1376.7571\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1898205.7500 - mae: 1376.5864\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1897732.0000 - mae: 1376.4148\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1897276.5000 - mae: 1376.2495\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1896830.6250 - mae: 1376.0878\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1896388.2500 - mae: 1375.9274\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1895942.2500 - mae: 1375.7654\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1895492.8750 - mae: 1375.6025\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1895042.0000 - mae: 1375.4391\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1894589.1250 - mae: 1375.2748\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1894132.5000 - mae: 1375.1091\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1893672.2500 - mae: 1374.9423\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1893208.5000 - mae: 1374.7740\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1892740.8750 - mae: 1374.6045\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1892270.2500 - mae: 1374.4337\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1891795.6250 - mae: 1374.2615\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1891317.3750 - mae: 1374.0880\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1890835.6250 - mae: 1373.9131\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1890350.2500 - mae: 1373.7369\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1889861.1250 - mae: 1373.5596\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1889368.5000 - mae: 1373.3806\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1888872.5000 - mae: 1373.2006\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1888372.6250 - mae: 1373.0190\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1887869.1250 - mae: 1372.8362\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1887362.2500 - mae: 1372.6520\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1886851.6250 - mae: 1372.4666\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1886337.6250 - mae: 1372.2798\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1885819.6250 - mae: 1372.0916\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1885298.2500 - mae: 1371.9020\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1884773.3750 - mae: 1371.7112\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1884244.6250 - mae: 1371.5190\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1883712.5000 - mae: 1371.3256\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1883176.5000 - mae: 1371.1306\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1882636.8750 - mae: 1370.9344\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1882093.7500 - mae: 1370.7369\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1881547.1250 - mae: 1370.5380\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1880996.8750 - mae: 1370.3378\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1880443.1250 - mae: 1370.1364\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1879885.3750 - mae: 1369.9333\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1879324.5000 - mae: 1369.7291\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1878759.6250 - mae: 1369.5234\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1878191.1250 - mae: 1369.3164\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1877619.1250 - mae: 1369.1080\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1877043.6250 - mae: 1368.8984\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1876464.5000 - mae: 1368.6875\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1875881.6250 - mae: 1368.4751\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1875295.1250 - mae: 1368.2615\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1874705.3750 - mae: 1368.0465\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1874111.7500 - mae: 1367.8301\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1873514.2500 - mae: 1367.6122\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1872913.6250 - mae: 1367.3932\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1872309.1250 - mae: 1367.1727\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1871700.8750 - mae: 1366.9509\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1871089.3750 - mae: 1366.7279\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1870474.0000 - mae: 1366.5033\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1869855.3750 - mae: 1366.2776\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1869232.6250 - mae: 1366.0503\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1868606.6250 - mae: 1365.8218\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1867976.8750 - mae: 1365.5918\n",
      "Epoch 176/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1867343.7500 - mae: 1365.3606\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1866706.8750 - mae: 1365.1281\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1866066.5000 - mae: 1364.8939\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1865422.6250 - mae: 1364.6587\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1864774.6250 - mae: 1364.4220\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1864123.6250 - mae: 1364.1840\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1863468.7500 - mae: 1363.9447\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1862810.5000 - mae: 1363.7040\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1862148.5000 - mae: 1363.4618\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1861482.7500 - mae: 1363.2184\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1860813.7500 - mae: 1362.9735\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1860140.8750 - mae: 1362.7274\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1859464.6250 - mae: 1362.4800\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1858784.8750 - mae: 1362.2311\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1858101.3750 - mae: 1361.9810\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1857414.3750 - mae: 1361.7292\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1856723.8750 - mae: 1361.4764\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1856029.6250 - mae: 1361.2223\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1855331.7500 - mae: 1360.9666\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1854630.6250 - mae: 1360.7096\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1853925.7500 - mae: 1360.4513\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1853217.6250 - mae: 1360.1917\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1852505.6250 - mae: 1359.9305\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1851790.0000 - mae: 1359.6682\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1851070.8750 - mae: 1359.4045\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1850348.5000 - mae: 1359.1393\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1849622.2500 - mae: 1358.8728\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1848892.5000 - mae: 1358.6051\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1848159.3750 - mae: 1358.3359\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1847422.5000 - mae: 1358.0654\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1846682.2500 - mae: 1357.7936\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1845938.3750 - mae: 1357.5204\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1845191.1250 - mae: 1357.2458\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1844440.2500 - mae: 1356.9698\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1843685.7500 - mae: 1356.6927\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1842927.7500 - mae: 1356.4141\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1842166.5000 - mae: 1356.1342\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1841401.6250 - mae: 1355.8529\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1840633.0000 - mae: 1355.5701\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1839861.0000 - mae: 1355.2861\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1839085.6250 - mae: 1355.0007\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1838306.6250 - mae: 1354.7140\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1837524.0000 - mae: 1354.4260\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1836738.2500 - mae: 1354.1366\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1835948.6250 - mae: 1353.8458\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1835155.6250 - mae: 1353.5537\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1834359.3750 - mae: 1353.2604\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1833559.3750 - mae: 1352.9655\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1832755.8750 - mae: 1352.6693\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1831949.0000 - mae: 1352.3718\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1831138.7500 - mae: 1352.0730\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1830324.8750 - mae: 1351.7729\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1829507.7500 - mae: 1351.4713\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1828686.8750 - mae: 1351.1685\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1827862.6250 - mae: 1350.8641\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1827035.1250 - mae: 1350.5586\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1826203.8750 - mae: 1350.2517\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1825369.3750 - mae: 1349.9436\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1824531.3750 - mae: 1349.6339\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1823689.7500 - mae: 1349.3229\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1822845.0000 - mae: 1349.0107\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1821996.8750 - mae: 1348.6970\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1821145.1250 - mae: 1348.3822\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1820290.0000 - mae: 1348.0658\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1819431.6250 - mae: 1347.7483\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1818569.3750 - mae: 1347.4293\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1817704.1250 - mae: 1347.1090\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1816835.3750 - mae: 1346.7874\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1815963.0000 - mae: 1346.4642\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1815087.3750 - mae: 1346.1400\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1814208.5000 - mae: 1345.8143\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1813326.1250 - mae: 1345.4874\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1812440.2500 - mae: 1345.1589\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1811551.1250 - mae: 1344.8295\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1810658.5000 - mae: 1344.4983\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1809762.7500 - mae: 1344.1660\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1808863.6250 - mae: 1343.8324\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1807960.8750 - mae: 1343.4974\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1807054.8750 - mae: 1343.1610\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1806145.6250 - mae: 1342.8234\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1805232.6250 - mae: 1342.4844\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1804316.6250 - mae: 1342.1442\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1803397.3750 - mae: 1341.8024\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1802474.5000 - mae: 1341.4595\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1801548.5000 - mae: 1341.1150\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1800619.2500 - mae: 1340.7695\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1799686.3750 - mae: 1340.4225\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1798750.3750 - mae: 1340.0742\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1797811.0000 - mae: 1339.7246\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1796868.5000 - mae: 1339.3737\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1795922.5000 - mae: 1339.0215\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1794973.1250 - mae: 1338.6678\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1794020.6250 - mae: 1338.3130\n",
      "Epoch 269/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1793064.7500 - mae: 1337.9567\n",
      "Epoch 270/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1792105.6250 - mae: 1337.5992\n",
      "Epoch 271/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1791143.2500 - mae: 1337.2405\n",
      "Epoch 272/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1790177.6250 - mae: 1336.8802\n",
      "Epoch 273/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1789208.6250 - mae: 1336.5187\n",
      "Epoch 274/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1788236.2500 - mae: 1336.1559\n",
      "Epoch 275/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1787260.7500 - mae: 1335.7917\n",
      "Epoch 276/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1786282.0000 - mae: 1335.4263\n",
      "Epoch 277/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1785300.0000 - mae: 1335.0596\n",
      "Epoch 278/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1784314.7500 - mae: 1334.6914\n",
      "Epoch 279/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1783326.2500 - mae: 1334.3220\n",
      "Epoch 280/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1782334.6250 - mae: 1333.9514\n",
      "Epoch 281/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1781339.6250 - mae: 1333.5795\n",
      "Epoch 282/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1780341.3750 - mae: 1333.2059\n",
      "Epoch 283/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1779340.0000 - mae: 1332.8314\n",
      "Epoch 284/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1778335.3750 - mae: 1332.4556\n",
      "Epoch 285/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1777327.6250 - mae: 1332.0781\n",
      "Epoch 286/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1776316.6250 - mae: 1331.6997\n",
      "Epoch 287/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1775302.3750 - mae: 1331.3199\n",
      "Epoch 288/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1774284.6250 - mae: 1330.9386\n",
      "Epoch 289/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1773264.2500 - mae: 1330.5563\n",
      "Epoch 290/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1772240.2500 - mae: 1330.1724\n",
      "Epoch 291/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1771213.6250 - mae: 1329.7874\n",
      "Epoch 292/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1770183.2500 - mae: 1329.4010\n",
      "Epoch 293/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1769149.7500 - mae: 1329.0133\n",
      "Epoch 294/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1768113.3750 - mae: 1328.6241\n",
      "Epoch 295/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1767073.7500 - mae: 1328.2340\n",
      "Epoch 296/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1766030.8750 - mae: 1327.8424\n",
      "Epoch 297/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1764985.0000 - mae: 1327.4495\n",
      "Epoch 298/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1763935.7500 - mae: 1327.0553\n",
      "Epoch 299/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1762883.6250 - mae: 1326.6598\n",
      "Epoch 300/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1761828.2500 - mae: 1326.2631\n",
      "Epoch 301/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1760769.7500 - mae: 1325.8650\n",
      "Epoch 302/400\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1759708.0000 - mae: 1325.4656\n",
      "Epoch 303/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1758643.6250 - mae: 1325.0651\n",
      "Epoch 304/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1757575.6250 - mae: 1324.6630\n",
      "Epoch 305/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1756504.6250 - mae: 1324.2598\n",
      "Epoch 306/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1755430.5000 - mae: 1323.8552\n",
      "Epoch 307/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1754353.3750 - mae: 1323.4493\n",
      "Epoch 308/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1753273.1250 - mae: 1323.0424\n",
      "Epoch 309/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1752190.0000 - mae: 1322.6339\n",
      "Epoch 310/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1751103.6250 - mae: 1322.2242\n",
      "Epoch 311/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1750014.1250 - mae: 1321.8134\n",
      "Epoch 312/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1748921.6250 - mae: 1321.4010\n",
      "Epoch 313/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1747826.0000 - mae: 1320.9874\n",
      "Epoch 314/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1746727.6250 - mae: 1320.5728\n",
      "Epoch 315/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1745625.7500 - mae: 1320.1566\n",
      "Epoch 316/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1744521.0000 - mae: 1319.7391\n",
      "Epoch 317/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1743413.3750 - mae: 1319.3206\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 1742302.6250 - mae: 1318.9006\n",
      "Epoch 319/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1741188.8750 - mae: 1318.4794\n",
      "Epoch 320/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1740072.2500 - mae: 1318.0570\n",
      "Epoch 321/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1738952.2500 - mae: 1317.6333\n",
      "Epoch 322/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1737829.6250 - mae: 1317.2081\n",
      "Epoch 323/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1736703.6250 - mae: 1316.7819\n",
      "Epoch 324/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1735574.8750 - mae: 1316.3541\n",
      "Epoch 325/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1734443.1250 - mae: 1315.9254\n",
      "Epoch 326/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1733308.2500 - mae: 1315.4952\n",
      "Epoch 327/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1732170.5000 - mae: 1315.0640\n",
      "Epoch 328/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1731029.6250 - mae: 1314.6313\n",
      "Epoch 329/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1729886.0000 - mae: 1314.1973\n",
      "Epoch 330/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1728739.6250 - mae: 1313.7622\n",
      "Epoch 331/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1727589.8750 - mae: 1313.3258\n",
      "Epoch 332/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1726437.6250 - mae: 1312.8881\n",
      "Epoch 333/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1725281.8750 - mae: 1312.4489\n",
      "Epoch 334/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1724123.6250 - mae: 1312.0087\n",
      "Epoch 335/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1722962.2500 - mae: 1311.5671\n",
      "Epoch 336/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1721797.8750 - mae: 1311.1246\n",
      "Epoch 337/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1720630.8750 - mae: 1310.6804\n",
      "Epoch 338/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1719460.6250 - mae: 1310.2351\n",
      "Epoch 339/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1718287.6250 - mae: 1309.7887\n",
      "Epoch 340/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1717111.8750 - mae: 1309.3408\n",
      "Epoch 341/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1715933.2500 - mae: 1308.8918\n",
      "Epoch 342/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1714751.6250 - mae: 1308.4415\n",
      "Epoch 343/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1713567.0000 - mae: 1307.9899\n",
      "Epoch 344/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1712379.6250 - mae: 1307.5371\n",
      "Epoch 345/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1711189.3750 - mae: 1307.0830\n",
      "Epoch 346/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1709996.3750 - mae: 1306.6278\n",
      "Epoch 347/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1708800.3750 - mae: 1306.1713\n",
      "Epoch 348/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1707601.6250 - mae: 1305.7135\n",
      "Epoch 349/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1706399.7500 - mae: 1305.2544\n",
      "Epoch 350/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1705195.3750 - mae: 1304.7941\n",
      "Epoch 351/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1703988.2500 - mae: 1304.3326\n",
      "Epoch 352/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1702778.1250 - mae: 1303.8698\n",
      "Epoch 353/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1701565.0000 - mae: 1303.4059\n",
      "Epoch 354/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1700349.2500 - mae: 1302.9406\n",
      "Epoch 355/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1699130.8750 - mae: 1302.4741\n",
      "Epoch 356/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1697909.6250 - mae: 1302.0063\n",
      "Epoch 357/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1696685.6250 - mae: 1301.5374\n",
      "Epoch 358/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1695458.6250 - mae: 1301.0671\n",
      "Epoch 359/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1694228.8750 - mae: 1300.5957\n",
      "Epoch 360/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1692996.5000 - mae: 1300.1230\n",
      "Epoch 361/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1691761.1250 - mae: 1299.6490\n",
      "Epoch 362/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1690523.2500 - mae: 1299.1741\n",
      "Epoch 363/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1689282.6250 - mae: 1298.6978\n",
      "Epoch 364/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1688039.1250 - mae: 1298.2201\n",
      "Epoch 365/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1686793.0000 - mae: 1297.7413\n",
      "Epoch 366/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1685544.1250 - mae: 1297.2614\n",
      "Epoch 367/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1684292.5000 - mae: 1296.7799\n",
      "Epoch 368/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1683038.2500 - mae: 1296.2975\n",
      "Epoch 369/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1681781.1250 - mae: 1295.8138\n",
      "Epoch 370/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1680521.3750 - mae: 1295.3289\n",
      "Epoch 371/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1679258.8750 - mae: 1294.8427\n",
      "Epoch 372/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1677993.7500 - mae: 1294.3553\n",
      "Epoch 373/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1676726.0000 - mae: 1293.8668\n",
      "Epoch 374/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1675455.6250 - mae: 1293.3770\n",
      "Epoch 375/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1674182.2500 - mae: 1292.8859\n",
      "Epoch 376/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1672906.6250 - mae: 1292.3938\n",
      "Epoch 377/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1671628.1250 - mae: 1291.9003\n",
      "Epoch 378/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1670346.8750 - mae: 1291.4056\n",
      "Epoch 379/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1669063.1250 - mae: 1290.9098\n",
      "Epoch 380/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1667776.7500 - mae: 1290.4127\n",
      "Epoch 381/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1666487.6250 - mae: 1289.9144\n",
      "Epoch 382/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1665196.0000 - mae: 1289.4149\n",
      "Epoch 383/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1663901.8750 - mae: 1288.9143\n",
      "Epoch 384/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1662604.8750 - mae: 1288.4124\n",
      "Epoch 385/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1661305.6250 - mae: 1287.9092\n",
      "Epoch 386/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1660003.6250 - mae: 1287.4049\n",
      "Epoch 387/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1658698.7500 - mae: 1286.8994\n",
      "Epoch 388/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1657391.6250 - mae: 1286.3928\n",
      "Epoch 389/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1656081.7500 - mae: 1285.8848\n",
      "Epoch 390/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1654769.6250 - mae: 1285.3756\n",
      "Epoch 391/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1653454.6250 - mae: 1284.8655\n",
      "Epoch 392/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1652137.1250 - mae: 1284.3540\n",
      "Epoch 393/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1650817.1250 - mae: 1283.8413\n",
      "Epoch 394/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1649494.5000 - mae: 1283.3274\n",
      "Epoch 395/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1648169.3750 - mae: 1282.8123\n",
      "Epoch 396/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1646842.0000 - mae: 1282.2961\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 1645511.6250 - mae: 1281.7787\n",
      "Epoch 398/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1644179.2500 - mae: 1281.2600\n",
      "Epoch 399/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1642844.1250 - mae: 1280.7402\n",
      "Epoch 400/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1641506.2500 - mae: 1280.2192\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZiJAnphGS0bJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuG0lEQVR4nO3dd3hVZfb28e9KDyT0UBOkCiJSAxZQUUdE1MEuKiO2Qey+TtNRx9+M4zQd24yKDcvIgBUrFiyIHYIivQkCoQZCbyHJev84GzkygQTIyU65P9eVi32eXc46G3Judnsec3dERET2JS7sAkREpPJTWIiISKkUFiIiUiqFhYiIlEphISIipVJYiIhIqRQWIuXEzJ4xsz+XcdkfzOxnsa5JpLwoLEREpFQKCxERKZXCQmqU4PTPb8xsmpltMbOnzKyJmb1jZpvM7AMzqx+1/M/NbKaZrTezCWZ2WNS87mb2TbDeC0DKHu91uplNDdb9wsy6lLHGZ8zskaCmzWb2uZk1NbMHzGydmc0xs+5Ry99iZt8Hdcwys7P22N7lZjY7WPc9MzvkgHeg1FgKC6mJzgFOBg4FzgDeAX4PZBD5nbgBwMwOBUYDNwXzxgFvmlmSmSUBrwH/ARoALwXbJVi3OzASuApoCDwGvGFmyWWs8XzgdqARsAP4EvgmeP0ycF/Ust8DxwJ1gT8Cz5tZs6COQcFnOzv4DJ8Gn0lkvygspCb6l7uvcvdlRL48v3b3b919OzAW2PW/9guAt919vLvvBO4FUoFjgKOAROABd9/p7i8Dk6PeYxjwmLt/7e5F7v4skS/9o8pY41h3nxJV03Z3f87di4AXomrE3V9y9+XuXuzuLwDzgd7B7OHAX919trsXAn8BuunoQvaXwkJqolVR09tKeJ0WTDcHFu+a4e7FwFKgRTBvmf+0J87FUdOHAL8KTkGtN7P1QFawXnnWiJldEnW6az3QmcgRyK46Hoyalw9Y8BlEyiwh7AJEKrHlwBG7XpiZEfnCXwY40MLMLCowWhI5JQSRULnb3e+OZYHBEcITwEnAl+5eZGZTiQRCdB2jYlmHVH86shDZuxeB08zsJDNLBH5F5FTSF0SuIRQCN5hZopmdze5TPxD5Ah9uZkdaRG0zO83M0su5xtpEgisPwMwuI3JkscsI4FYzOzyYX9fMzivnGqQGUFiI7IW7zwWGAP8C1hC5GH6Guxe4ewGRi8aXEjm1cwHwatS6OcAvgX8D64AFwbLlXeMs4J9EwmsVkSOhz6PmjwX+Dowxs43ADODU8q5Dqj/T4EciIlIaHVmIiEipFBYiIlIqhYWIiJRKYSEiIqWqls9ZNGrUyFu1ahV2GSIiVcqUKVPWuHtGSfOqZVi0atWKnJycsMsQEalSzGzx3ubpNJSIiJRKYSEiIqVSWIiISKmq5TWLkuzcuZPc3Fy2b98edikxl5KSQmZmJomJiWGXIiLVRI0Ji9zcXNLT02nVqhWRzkOrJ3dn7dq15Obm0rp167DLEZFqosachtq+fTsNGzas1kEBYGY0bNiwRhxBiUjFqTFhAVT7oNilpnxOEak4NSosSuPurNiwjS07ClFvvCIiuyksohQUFZO/uYDv8zazYPVm8rcUUFxcfqGxfv16Hnnkkf1eb+DAgaxfv77c6hAR2V8KiyjJCfF0bFaHFvVScSB33VZmr9zIig3bKCgsOujt7y0sCgsL97neuHHjqFev3kG/v4jIgaoxd0OVVXyc0TAtmQa1k9iyo4i1W3awZlMBeZt2UCclkYZpSaQlJxzQdYFbbrmF77//nm7dupGYmEhKSgr169dnzpw5zJs3jzPPPJOlS5eyfft2brzxRoYNGwbs7r5k8+bNnHrqqfTt25cvvviCFi1a8Prrr5Oamlreu0FE5CdqZFj88c2ZzFq+sczLu8PO4mIKixx3J86MhHgjMX73gVmn5nW484zD97mdv/3tb8yYMYOpU6cyYcIETjvtNGbMmPHjLa4jR46kQYMGbNu2jV69enHOOefQsGHDn2xj/vz5jB49mieeeILzzz+fV155hSFDhuzHpxcR2X81Miz2lxkkxceRFA+Fxc7OomIKCospKComIS6OxHiDA7i00bt37588C/HQQw8xduxYAJYuXcr8+fP/Jyxat25Nt27dAOjZsyc//PDDgX4sEZEyq5FhUdoRQFlsLSgkf0sB67fupNid5IR48jZtp16tpJ8ccexL7dq1f5yeMGECH3zwAV9++SW1atWiX79+JT4rkZyc/ON0fHw827ZtO+jPIiJSmhoZFuWhVlICtZISaFbX2bBtJ+u2FLBiw3ZWbthBekoC9WolUiclkbi43dc20tPT2bRpU4nb27BhA/Xr16dWrVrMmTOHr776qqI+iohIqRQWByk+zmhQO4kGtZPYvrOIdVsLWLdlJxu37yTOjLqpidRNTSQtJYGGDRvSp08fOnfuTGpqKk2aNPlxOwMGDGDEiBEcdthhdOjQgaOOOirETyUi8lNWHR8+y87O9j0HP5o9ezaHHXZYhby/u7NlRyHrt+1kw7adFBU78XFG3ZRE6gTBERfjp6wr8vOKSPVgZlPcPbukeTqyiAEzIy0lkbSURJrXczZv3x0c+VsLiDcjPTWRuqkJpCf/9FSViEhlpLCIsTgz6qRGjiiKPRIcG7dFTlOt31pAnBnpKQnUTU0kPSWB+Dg9JykilU+NCgt3D7WTvejg2HWqasO2QjZujxx1mBlpyQnUSUkgLSWB5IT4A3qf6nhqUUTCVWPCIiUlhbVr11aabsp/cqrKU9haUMSG4Ihj2fqdACQlxJGenBBZLjm+TEcdu8azSElJifVHEJEapMaERWZmJrm5ueTl5YVdSqmsqJjthcVs3FnEssJiih2MSHgkJ8aRkhBPYnwce8u8XSPliYiUlxoTFomJiVVy5LiCwmK+WbKOifPy+HT+GqYv2wBAvVqJ9GnXiOPbZ3DsoY1oVlf9Q4lI7NSYW2eri7Wbd/DZgjV8On8NE+flsXrTDgDaNU7juCA4jmrdkNSkA7veISI1175unVVYVGHuzrxVm5k4L4+J8/OYtCifHYXFJMXH0at1fY5tn8Fx7TM4rFl6pbhOIyKVm8Kihti+s4hJi/L5dH4eE+etYe6qSNcijdKSOa59I449tBF922WQkZ5cypZEpCZSWNRQqzZu//Fax2cL1pC/pQCATs3qcOyhjTiufQbZreof8C26IlK9KCyE4mJn5vKNTJyfx8R5eUxZvI7CYqdWUjz9OmTQv1NTTujQmLq1EsMuVURCorCQ/7F5RyFffb+Wj+auZvysVeRt2kFCnHFUm4b0P7wJJ3dqojusRGqYUMLCzEYCpwOr3b1z0HYXMAgoBlYDl7r7cjOrCzwPtCRyO++97v50sM5Q4PZgs39292dLe2+Fxf4pLnam5q7n/ZmreH/mShau2QJAl8y69O/UhIFHNKNNRlrIVYpIrIUVFscBm4HnosKijrtvDKZvADq5+3Az+z1Q191/Z2YZwFygKZAG5ADZRMaimwL0dPd1+3pvhcXBWbB6M+/PWsn7M1cxdel6IHKd44yuzTm9SzOyGtQKt0ARiYlQep1194lm1mqPtuiBr2uzezBSB9Itcn9nGpAPFAKnAOPdPR/AzMYDA4DRsapbIs9stGvcjmv6tWPFhm28PW0Fb01bwd/fncPf351D16x6nNGlGad1aaZTVSI1REyvWQRh8dauI4ug7W7gEmADcIK755lZOvAG0BFIBy5w97fN7NdAirv/OVj3DmCbu99bwnsNA4YBtGzZsufixYtj9rlqqqX5W3l7+gre/G45M5dHcr9Xq/r8vFsLzujSjHq1kkKuUEQORmgXuEsKi6h5txIJgjvN7FygD3Az0BYYD3Ql8uVfprCIptNQsbcwbzNvT1vBm9OWM2/VZpLi4/hZp8ac0yOT4w7NKPM45CJSeVTWwY9GAeOAO4HLgL95JLkWmNkiIkcZy4B+UetkAhMqtkwpSZuMNK4/qT3XndiOmcs38so3ubwxdTnjpq+kUVoSP+/agnN6tuDw5nXDLlVEykGFhoWZtXf3+cHLQcCcYHoJcBLwqZk1AToAC4EFwF/MrH6wXH/g1gosWUphZnRuUZfOLery+4GHMWFuHq9MyeU/X/3AyM8X0bFpOuf2zOSs7i1omKYnx0WqqljeDTWayFFBI2AVkSOIgUSCoBhYDAx392Vm1hx4BmhGpDfuv7n788F2Lgd+H2z27l231O6LTkOFb92WAt6ctpxXvlnGd0vXkxhv9O/UlMG9s+jTtpGGkhWphPRQnoRq3qpNjJm0lFe/zWX91p1k1k/l/OwszsvO1N1UIpWIwkIqhR2FRbw/cxVjJi/h8wVriTPo16ExF/TK4sSOjXVRXCRkCgupdJas3cqLOUt5acpSVm3cQUZ6Muf2zOSC7CxaNaoddnkiNZLCQiqtwqJiJszNY8zkpXw8dzVFxc7RbRoyuHcWpxzelJRE9YgrUlEUFlIlrNq4nZen5PLC5KUsyd9K3dREzuregsG9s+jYtE7Y5YlUewoLqVKKi52vFq5l9OSlvDdjJQVFxXTNqseFvbI4vWtz0pJrzNDxIhVKYSFV1rotBYz9dhljJi9h3qrN1EqK54wuzRncO4tuWfU0XKxIOVJYSJXn7ny7dD0vTFrKm9OWs7WgiA5N0rmwdxbnZmfpaEOkHCgspFrZvKOQN79bzphJS/gudwPpyQmc3yuLS49ppe7TRQ6CwkKqre+WruepzxYxbvoKit055fCmXN63NdmH1NcpKpH9pLCQam/Fhm089+Vi/vv1EjZs20mXzLpc3qc1p3Vppof9RMpIYSE1xtaCQl75ZhlPf7aIhWu20LxuCr88rg0X9MqiVpKua4jsi8JCapziYmfCvNWMmLCQST/kU79WIpf1ac0lRx+iQZpE9kJhITVazg/5PDrhez6cs5raSfFcdGRLrjy2DU3qpIRdmkilorAQAWav2Mhjn3zPm9NWEG/G2T1acE2/drRsqDuoREBhIfITS9Zu5YlPF/JCzlKKi51zemRy3YntdNut1HgKC5ESrNq4nUcnfM9/Jy2huNg5t2cm156g0JCaS2Ehsg8rN2xnxCe7Q+O87Eyu6afQkJpHYSFSBis3bOfRCQsYPWkpxe6c3yuLG05sT9O6uhAuNYPCQmQ/rNiwjUcnfM/oSUuIM+OyPq25+vi21K2VGHZpIjGlsBA5AEvzt3L/+HmMnbqM9OQEhvdry2XHtCY1SQMySfWksBA5CLNXbOTe9+by4ZzVNE5P5saftef87Cx1IyLVzr7CQv/aRUpxWLM6PHVpL14afjQtG9TitrEzOPm+Txg3fQXV8T9bIiVRWIiUUa9WDXhp+NE8NTSb5IR4rhn1Dec/9iXfLV0fdmkiMaewENkPZsZJhzXh7Rv68pezjmDRmi0Mevhz/t8LU1mxYVvY5YnEjMJC5AAkxMdx0ZEt+fjX/bimX1venr6CE+6dwH3vz2XLjsKwyxMpdwoLkYOQnpLIbwd05KNfHc/JnZry0EcLOOHeCbwYdCUiUl3ELCzMbKSZrTazGVFtd5nZNDObambvm1nzqHn9gvaZZvZJVPsAM5trZgvM7JZY1StyMDLr1+JfF3bnlauPoUX9VH778jTOeuRzXc+QaiNmt86a2XHAZuA5d+8ctNVx943B9A1AJ3cfbmb1gC+AAe6+xMwau/tqM4sH5gEnA7nAZOBCd5+1r/fWrbMSJnfn9anLuXvcbNZs3sHgXln85pSONKitcTSkcgvl1ll3nwjk79G2MeplbWBXUl0EvOruS4LlVgftvYEF7r7Q3QuAMcCgWNUsUh7MjDO7t+CjXx3PL49tw0s5uZxw7wT+8+UPFOnUlFRRFX7NwszuNrOlwMXAH4LmQ4H6ZjbBzKaY2SVBewtgadTquUFbSdsdZmY5ZpaTl5cXq/JFyiw9JZHfDzyMd286ls4t6nDH6zM541+fkfNDfukri1QyFR4W7n6bu2cBo4DrguYEoCdwGnAKcIeZHbqf233c3bPdPTsjI6NcaxY5GO0ap/P8FUfyyMU9WL+1gHNHfMnNL05l7eYdYZcmUmZh3g01CjgnmM4F3nP3Le6+BpgIdAWWAVlR62QGbSJVipkx8IhmfPCr47n2hLa8+d1yTrrvE17MWaqnwKVKqNCwMLP2US8HAXOC6deBvmaWYGa1gCOB2UQuaLc3s9ZmlgQMBt6oyJpFylOtpAR+c0pHxt1wLO0bp/Hbl6cx+PGvWLB6c9iliexTLG+dHQ18CXQws1wzuwL4m5nNMLNpQH/gRgB3nw28C0wDJgFPuvsMdy8kcqrqPSLh8aK7z4xVzSIVpX2TdF4YdjR/P+cI5qzcxMAHP+W+8fPYvrMo7NJESqReZ0VCtmbzDv781ixem7qcNo1q8+ezOnNM20ZhlyU1kHqdFanEGqUl88Dg7vznit4UuXPRE1/z25e/Y8O2nWGXJvIjhYVIJXFs+wzeu+k4ru7Xlle+WUb/+z/hw9mrwi5LBFBYiFQqKYnx/G5AR8Zecwz1ayVxxbM53DTmW9ZtKQi7NKnhFBYilVCXzHq8cV1fbvpZe96atoKT7/+Ed6avCLssqcEUFiKVVFJCHDf97FDevL4vTeumcPWob7hm1BTyNulhPql4CguRSu6wZnV47Zo+/HZABz6YtZr+93/C61OX6WE+qVAKC5EqICE+jmv6tWPcjX1p1ag2N46ZynWjv2X9Vl3LkIqhsBCpQto1Tuelq47mN6d04L0ZK+l//0QmzF1d+ooiB0lhIVLFJMTHce0J7Xjt2j7UTU3k0qcnc/tr09laoOFcJXYUFiJVVOcWdXnz+r5c2bc1o75ewmkPfca3S9aFXZZUUwoLkSosJTGe20/vxH+vPIqCwmLOHfEl970/l51FxWGXJtWMwkKkGji6bUPeuelYzuzWgoc+WsDZj3zBwjz1ZCvlR2EhUk3USUnkn+d3ZcSQnuSu28rp//qMlzRehpQThYVINTOgc1PeufE4umbW4zcvT+OGMVPZuF2dEsrBUViIVENN66bw/JVH8ptTOjBu+goGPvgp3+jitxwEhYVINRUfZ1x7QjteGn40AOeN+JKHP15AUbFOS8n+U1iIVHM9WtZn3I3HMvCIZtzz3lwufvIrVm7YHnZZUsUoLERqgDopiTw0uBv3nNuFabkbGPDgRI2VIftFYSFSQ5gZ52Vn8db1fWlRL5Urns3hr+/M1jMZUiYKC5Eapk1GGq9cfQwXH9mSxz5ZyEVP6LSUlE5hIVIDpSTGc/dZR/Dg4G7MXL6R0x76lE/n54VdllRiCguRGmxQtxa8cV1fGqYlccnISdw/fp7ulpISKSxEarh2jdN47do+nNW9BQ9+OJ+hIyexZrNG45OfUliICLWSEvjneV35xzldmPxDPgMf/JSvF64NuyypRBQWIgJE7pY6v1cWY6/pQ+3kBC568mue+myR+pYSQGEhInvo1LwOb1zXh5M6Nuaut2Zx0wtT2VZQFHZZErIyh4WZHWJmPwumU80svZTlR5rZajObEdV2l5lNM7OpZva+mTXfY51eZlZoZudGtQ01s/nBz9CyfzQROVDpKYmMGNKTX/c/lDe+W85Zj3zOkrVbwy5LQlSmsDCzXwIvA48FTZnAa6Ws9gwwYI+2e9y9i7t3A94C/hD1HvHA34H3o9oaAHcCRwK9gTvNrH5ZahaRgxMXZ1x3YntGXtqL5eu3cca/P9N43zVYWY8srgX6ABsB3H0+0HhfK7j7RCB/j7aNUS9rA9EnQ68HXgGi/zWeAox393x3XweM538DSERi6IQOjXnz+r40q5vCZc9M5uGPF1Cs22trnLKGxQ53L9j1wswS+OkXfZmZ2d1mthS4mODIwsxaAGcBj+6xeAtgadTr3KCtpO0OM7McM8vJy9PDRSLl6ZCGtXn1mmM4o0tz7nlvLsOfn8ImjZFRo5Q1LD4xs98DqWZ2MvAS8OaBvKG73+buWcAo4Lqg+QHgd+5+wJ3UuPvj7p7t7tkZGRkHuhkR2YtaSQk8OLgbd5zeiQ/nrGbQw5/zvYZurTHKGha3AHnAdOAqYBxw+0G+9yjgnGA6GxhjZj8A5wKPmNmZwDIgK2qdzKBNREJgZlzRtzXPX3Ek67fu5MyHP+eTeTqSrwnKFBbuXuzuT7j7ee5+bjC936ehzKx91MtBwJxg+63dvZW7tyJyIf0ad38NeA/ob2b1gwvb/YM2EQnR0W0b8vq1fWhRL5XLnp6k5zFqgISyLBR8yf8V6ASk7Gp39zb7WGc00A9oZGa5RO5qGmhmHYBiYDEwfF/v6+75ZnYXMDlo+pO75+9rHRGpGFkNavHK1cfw/16Yyl1vzWLuyo3cdWZnkhPiwy5NYsDK8r8BM/uMyJf9/cAZwGVAnLv/YZ8rhiQ7O9tzcnLCLkOkRigudu7/YB7/+mgBvVrV59EhPWmUlhx2WXIAzGyKu2eXNK+s1yxS3f1DIuGy2N3/DzitvAoUkaorLs74Vf8OPHRhd6blbmDQvz9n1vKNpa8oVUqZb501szhgvpldZ2ZnAWkxrEtEqpifd23OS8OPprC4mHNHfMG7M1aGXZKUo7KGxY1ALeAGoCcwBLgkVkWJSNXUJbMeb17Xl/ZN0hn+/BT+/dF8XfiuJsoaFg78B3iDyG2uhwJPxKooEam6GtdJ4YVhR3Fmt+bc+/48fv3SNAoKNc53VVemu6GIPBPxGyLPWehvXUT2KSUxnvsv6EarRrV54IP5LFu/lceGZFO3VmLYpckBKuuRRZ67v+Hui4IL3IvdfXFMKxORKs3MuOlnh3L/BV2ZsngdZz2qnmursrKGxZ1m9qSZXWhmZ+/6iWllIlItnNU9k+evOJL8LQWc+cjnTFmsR6WqorKGxWVANyI9vp4R/Jweo5pEpJo5sk1DXr36GOqkJHDhE1/z5nfLwy5J9lNZr1n0cvcOMa1ERKq1NhlpvHpNH676Tw7Xj/6WJflbuaZfW8ws7NKkDMp6ZPGFmXWKaSUiUu01qJ3E81ceyaBuka7Of/fKNHYW6Z6ZqqCsRxZHAVPNbBGwAzDA3b1LzCoTkWopOSGeBy7oxiENa/PQh/NZuXEHj17cg9rJZf06kjCU9W9Ho9OJSLkxM24++VBa1Evh92NnMPjxrxh5aS8y0tWnVGVV1i7KF5f0E+viRKR6u6BXS564pCcLVm/mnEe/YNGaLWGXJHtR1msWIiIxcWLHJowedhSbdxRyzqNfMHXp+rBLkhIoLEQkdN2y6vHy8KOpnRzPhY9/xUdzVoVdkuxBYSEilUKbjDRevboPbRvX5pfPTeGFyUvCLkmiKCxEpNLISE9mzLCj6dOuEb97ZToPfqBeaysLhYWIVCppyQk8NTSbs3u04P4P5vH7sTMo1LMYodONzSJS6STGx/HP87rStE4Kj0z4nnVbCnjwwm4a3ztEOrIQkUrJzPjtgI7ccXon3p25ksufmczmHYVhl1VjKSxEpFK7om9r/nleV75amM/FT37Nui0FYZdUIyksRKTSO6dnJiOG9GT2io2c/9iXrNywPeySahyFhYhUCSd3asKzl/VmxYbteto7BAoLEakyjm7bkNG/PIptO4s4b8SXzFq+MeySagyFhYhUKUdk1uXFq44mMd644PEvyflBI+9VhJiFhZmNNLPVZjYjqu0uM5tmZlPN7H0zax60Xxy0TzezL8ysa9Q6A8xsrpktMLNbYlWviFQd7Rqn8fLVx5CRlsyQp77m47mrwy6p2ovlkcUz/G/X5ve4exd37wa8BfwhaF8EHO/uRwB3AY8DmFk88DBwKtAJuFCDMIkIQIt6qbw4/GjaZqTxy2dzNFRrjMUsLNx9IpC/R1v0CcbagAftX7j7uqD9KyAzmO4NLHD3he5eAIwBBsWqZhGpWhqlJTN62FH0aFmfG8d8y8tTcsMuqdqq8GsWZna3mS0FLmb3kUW0K4B3gukWwNKoeblBm4gIAHVSEnnm8l4c07YRv37pO0Z9raF2YqHCw8Ldb3P3LGAUcF30PDM7gUhY/G5/t2tmw8wsx8xy8vLyyqdYEakSaiUl8OTQbE7s2Jjbxs5g5GeLwi6p2gnzbqhRwDm7XphZF+BJYJC7rw2alwFZUetkBm3/w90fd/dsd8/OyMiIUckiUlmlJMYzYkhPTu3clD+9NYtHJiwIu6RqpULDwszaR70cBMwJ2lsCrwK/cPd5UctMBtqbWWszSwIGA29UVL0iUrUkJcTxrwu7M6hbc/7x7lzue3+uujgvJzHrddbMRgP9gEZmlgvcCQw0sw5AMbAYGB4s/gegIfCImQEUBkcJhWZ2HfAeEA+MdPeZsapZRKq+hPg47ju/GykJ8Tz00QK2FxZz66kdCb5b5ADFLCzc/cISmp/ay7JXAlfuZd44YFw5liYi1Vx8nPHXs48gOTGOxycuZPvOIv7vjMOJi1NgHCiNZyEi1VJcnPHHnx9OSmI8j09cyI6dxfzl7COIV2AcEIWFiFRbZsatp3YkJTGehz6cT0FRMfee11WBcQAUFiJSrZkZN598KMkJcdzz3lwABcYBUFiISI1w7QntALjnvcgdUv88v5sCYz8oLESkxogODECBsR8UFiJSo1x7QjvM4B/vzsWBf57XlYR4jdZQGoWFiNQ41/SLHGH8493gCEOBUSqFhYjUSNf0a4dh/P3dObjDfecrMPZFYSEiNdbV/doCRAIDuF+BsVcKCxGp0a7u1xYz+Ns7cwAFxt4oLESkxht+fOQIY1dgPHCB7pLak8JCRISfBkZSfBz3nNtFfUlFUViIiASGH9+WgsJi7hs/j6SEOP5yVmf1VhtQWIiIRLn+xHbsKCzi4Y+/JzkhjjvP6KTAQGEhIvITZsav+3dg+85invpsEckJcdyi8TAUFiIiezIzbj/tMHYUFvHYxIUkJ8Zz88mHhl1WqBQWIiIlMDP+9PPOFBQW89CH80lOiPuxb6maSGEhIrIXcXHGX8/uQkFhMfe8N5fkhDiuPLZN2GWFQmEhIrIP8XHGved1paComD+/PZukhDguObpV2GVVOIWFiEgpEuLjeHBwdwoKv+EPr88kOSGOC3q1DLusCqVn2kVEyiAxPo6HL+7O8YdmcMur03nzu+Vhl1ShFBYiImWUnBDPiCE96XVIA/7fC1P5eM7qsEuqMAoLEZH9kJoUz5OXZtOxWTrDn5/C1wvXhl1ShVBYiIjspzopiTx7WW8y66dyxbM5TM/dEHZJMaewEBE5AA3Tknn+yiOpm5rI0KcnsWD1prBLiimFhYjIAWpWN5VRVx5JnBlDnpzE0vytYZcUMzELCzMbaWarzWxGVNtdZjbNzKaa2ftm1jxoNzN7yMwWBPN7RK0z1MzmBz9DY1WviMiBaNWoNs9f2ZttO4sY8tTXrN64PeySYiKWRxbPAAP2aLvH3bu4ezfgLeAPQfupQPvgZxjwKICZNQDuBI4EegN3mln9GNYsIrLfOjatwzOX9SJv0w5+8dQk1m8tCLukchezsHD3iUD+Hm0bo17WBjyYHgQ85xFfAfXMrBlwCjDe3fPdfR0wnv8NIBGR0HVvWZ8nL8lm0dotDH16Mpt3FIZdUrmq8GsWZna3mS0FLmb3kUULYGnUYrlB297aS9ruMDPLMbOcvLy88i9cRKQUx7RrxL8v7M6MZRsY9lwO23cWhV1SuanwsHD329w9CxgFXFeO233c3bPdPTsjI6O8Nisisl/6H96Ue8/rwhffr+XmF6dSVOylr1QFhHk31CjgnGB6GZAVNS8zaNtbu4hIpXVW90xuP+0wxk1fyZ1vzMC96gdGhYaFmbWPejkImBNMvwFcEtwVdRSwwd1XAO8B/c2sfnBhu3/QJiJSqV15bBuuOr4Nz3+1hAc/nB92OQctZr3OmtlooB/QyMxyidzVNNDMOgDFwGJgeLD4OGAgsADYClwG4O75ZnYXMDlY7k/u/pOL5iIildUtAzqydnMBD3wwn0ZpyQw56pCwSzpgVh0Oj/aUnZ3tOTk5YZchIkJhUTFX/WcKH81dzcMX9WDgEc3CLmmvzGyKu2eXNE9PcIuIxFBCfBz/vqgHPVrW56YxU/ni+zVhl3RAFBYiIjGWmhTPU0OzadWoFsOem8KMZVWv40GFhYhIBahXK4lnL+9NnZQELn16MovXbgm7pP2isBARqSDN6qby3BW9KSwu5hdPTWL1pqrTj5TCQkSkArVrnM7Tl0b6kbp05GQ2bd8ZdkllorAQEalg3VvW59EhPZi7ahPXjPqGnUXFYZdUKoWFiEgI+nVozF/PPoJP56/hllemV/qnvGP2UJ6IiOzb+dlZLF+/jQc+mE+Leinc3L9D2CXtlcJCRCREN57UnuXrt/HQRwtoXi+Vwb1bhl1SiRQWIiIhMjPuPusIVm7cwW2vzaBJnRRO6Ng47LL+h65ZiIiELDE+jkcu7kHHpulc+99vmJ5b+R7aU1iIiFQCackJPH1pL+rXSuKyZyazNH9r2CX9hMJCRKSSaFwnhWcv70VBYRFDn57Eui2VZyxvhYWISCXSrnE6Tw7tRW7+Nn5ZiYZmVViIiFQyvVs34L4LupKzeB03vziV4kowNKvCQkSkEjq9S/Mfh2b989uzwy5Ht86KiFRWV/RtTe66bYz8fBGHNKzF0GNahVaLwkJEpJIyM+44vRO567bxxzdnktUglRM7NgmlFp2GEhGpxOLjjAcHd+OwZnW4/r/fMmv5xlDqUFiIiFRytZMTeGpoL9JTErni2cms2ljx42AoLEREqoCmdVN46tJsNmzbyRXPTmZrQWGFvr/CQkSkiji8eV3+fVF3Zi3fyI1jplJUgbfUKixERKqQEzs24Y7TOzF+1ir+9k7F3VKru6FERKqYy/q05oc1W3ji00W0alSbi488JObvqbAQEamC7ji9E0vyt/KH12eSWb8Wxx+aEdP302koEZEqKCE+jn9d1IP2jdO4btQ3zF25KabvF7OwMLORZrbazGZEtd1jZnPMbJqZjTWzekF7opk9a2bTzWy2md0atc4AM5trZgvM7JZY1SsiUtWkJScw8tJepCbFc/kzk8nbtCNm7xXLI4tngAF7tI0HOrt7F2AesCsUzgOS3f0IoCdwlZm1MrN44GHgVKATcKGZdYphzSIiVUrzeqk8NbQX+VsKuDKGvdTGLCzcfSKQv0fb++6+6+bgr4DMXbOA2maWAKQCBcBGoDewwN0XunsBMAYYFKuaRUSqoiMy6/LA4G5My13Pr176Lia91IZ5zeJy4J1g+mVgC7ACWALc6+75QAtgadQ6uUHb/zCzYWaWY2Y5eXl5sataRKQSOuXwptwyoCNtM9Jisv1Q7oYys9uAQmBU0NQbKAKaA/WBT83sg/3Zprs/DjwOkJ2dHX7n7yIiFeyq49vGbNsVHhZmdilwOnCSu+/6Ur8IeNfddwKrzexzIJvIUUVW1OqZwLIKLFdERKjg01BmNgD4LfBzd48ejXwJcGKwTG3gKGAOMBlob2atzSwJGAy8UZE1i4hIbG+dHQ18CXQws1wzuwL4N5AOjDezqWY2Ilj8YSDNzGYSCYin3X1acDH8OuA9YDbworvPjFXNIiJSMtt9Jqj6yM7O9pycnLDLEBGpUsxsirtnlzRPT3CLiEipFBYiIlIqhYWIiJRKYSEiIqWqlhe4zSwPWHwQm2gErCmncsqT6to/qmv/VNa6oPLWVt3qOsTdS+zrvFqGxcEys5y93REQJtW1f1TX/qmsdUHlra0m1aXTUCIiUiqFhYiIlEphUbLHwy5gL1TX/lFd+6ey1gWVt7YaU5euWYiISKl0ZCEiIqVSWIiISKkUFlHMbICZzTWzBWZ2S8i1/GBm04PeeXOCtgZmNt7M5gd/1q+gWkaa2WozmxHVVmItFvFQsA+nmVmPCq7r/8xsWbDfpprZwKh5twZ1zTWzU2JYV5aZfWxms8xsppndGLSHus/2UVeo+8zMUsxskpl9F9T1x6C9tZl9Hbz/C8EwBZhZcvB6QTC/VQXX9YyZLYraX92C9gr7tx+8X7yZfWtmbwWvY7u/3F0/kes28cD3QBsgCfgO6BRiPT8AjfZo+wdwSzB9C/D3CqrlOKAHMKO0WoCBRIbLNSLjknxdwXX9H/DrEpbtFPydJgOtg7/r+BjV1QzoEUynA/OC9w91n+2jrlD3WfC504LpRODrYD+8CAwO2kcAVwfT1wAjgunBwAsx2l97q+sZ4NwSlq+wf/vB+90M/Bd4K3gd0/2lI4vdegML3H2huxcAY4BBIde0p0HAs8H0s8CZFfGm7j4RyC9jLYOA5zziK6CemTWrwLr2ZhAwxt13uPsiYAGRv/NY1LXC3b8JpjcRGYulBSHvs33UtTcVss+Cz705eJkY/DiRAdFeDtr33F+79uPLwElmZhVY195U2L99M8sETgOeDF4bMd5fCovdWhAZxnWXXPb9ixRrDrxvZlPMbFjQ1sTdVwTTK4Em4ZS2z1oqw368LjgNMDLqVF0odQWH/N2J/K+00uyzPeqCkPdZcEplKrAaGE/kKGa9RwZA2/O9f6wrmL8BaFgRdbn7rv11d7C/7jez5D3rKqHm8vYAkVFHi4PXDYnx/lJYVF593b0HcCpwrZkdFz3TI8eUleK+58pUC/Ao0BboBqwA/hlWIWaWBrwC3OTuG6PnhbnPSqgr9H3m7kXu3g3IJHL00rGiayjJnnWZWWfgViL19QIaAL+ryJrM7HRgtbtPqcj3VVjstgzIinqdGbSFwt2XBX+uBsYS+QVateuwNvhzdVj17aOWUPeju68KfsGLgSfYfdqkQusys0QiX8ij3P3VoDn0fVZSXZVlnwW1rAc+Bo4mchonoYT3/rGuYH5dYG0F1TUgOJ3n7r4DeJqK3199gJ+b2Q9ETpefCDxIjPeXwmK3yUD74I6CJCIXgt4IoxAzq21m6bumgf7AjKCeocFiQ4HXw6gvsLda3gAuCe4MOQrYEHXqJeb2OEd8FpH9tquuwcGdIa2B9sCkGNVgwFPAbHe/L2pWqPtsb3WFvc/MLMPM6gXTqcDJRK6nfAycGyy25/7atR/PBT4KjtQqoq45UYFvRK4LRO+vmP89uvut7p7p7q2IfE995O4XE+v9VZ5X56v6D5G7GeYROV96W4h1tCFyF8p3wMxdtRA5z/ghMB/4AGhQQfWMJnJ6YieRc6FX7K0WIneCPBzsw+lAdgXX9Z/gfacFvyTNopa/LahrLnBqDOvqS+QU0zRgavAzMOx9to+6Qt1nQBfg2+D9ZwB/iPo9mETkwvpLQHLQnhK8XhDMb1PBdX0U7K8ZwPPsvmOqwv7tR9XYj913Q8V0f6m7DxERKZVOQ4mISKkUFiIiUiqFhYiIlEphISIipVJYiIhIqRQWIpWMmfXb1ZOoSGWhsBARkVIpLEQOkJkNCcY7mGpmjwWdzm0OOpebaWYfmllGsGw3M/sq6HxurO0ey6KdmX1gkTETvjGztsHm08zsZTObY2ajYtGrqsj+UFiIHAAzOwy4AOjjkY7mioCLgdpAjrsfDnwC3Bms8hzwO3fvQuTp3l3to4CH3b0rcAyRJ9Ih0iPsTUTGlGhDpD8gkdAklL6IiJTgJKAnMDn4T38qkY4Bi4EXgmWeB141s7pAPXf/JGh/Fngp6P+rhbuPBXD37QDB9ia5e27weirQCvgs5p9KZC8UFiIHxoBn3f3WnzSa3bHHcgfan86OqOki9LsqIdNpKJED8yFwrpk1hh/H1z6EyO/Urp4/LwI+c/cNwDozOzZo/wXwiUdGq8s1szODbSSbWa2K/BAiZaX/rYgcAHefZWa3ExnNMI5Iz7fXAluIDJJzO5HTUhcEqwwFRgRhsBC4LGj/BfCYmf0p2MZ5FfgxRMpMvc6KlCMz2+zuaWHXIVLedBpKRERKpSMLEREplY4sRESkVAoLEREplcJCRERKpbAQEZFSKSxERKRU/x/5fAjWbrVmrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFLpSwAea75u"
   },
   "source": [
    "## Make submission answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HveCB2AybIbj"
   },
   "outputs": [],
   "source": [
    "test_db = connect('./data/test.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "3X0kTpFgalGt",
    "outputId": "1a759f76-d207-4a58-bb66-70c497bb27f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Br</th>\n",
       "      <th>BrC</th>\n",
       "      <th>C</th>\n",
       "      <th>CC</th>\n",
       "      <th>CH</th>\n",
       "      <th>CN</th>\n",
       "      <th>CO</th>\n",
       "      <th>CS</th>\n",
       "      <th>H</th>\n",
       "      <th>HN</th>\n",
       "      <th>N</th>\n",
       "      <th>NN</th>\n",
       "      <th>O</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Br  BrC     C   CC    CH    CN   CO   CS     H   HN    N   NN    O    S\n",
       "1  0.0  0.0  14.0  8.0  21.0  10.0  2.0  2.0  22.0  1.0  4.0  0.0  2.0  1.0\n",
       "2  0.0  0.0  14.0  8.0  21.0  10.0  2.0  2.0  22.0  1.0  4.0  0.0  2.0  1.0\n",
       "3  0.0  0.0  14.0  8.0  21.0  10.0  2.0  2.0  22.0  1.0  4.0  0.0  2.0  1.0\n",
       "4  0.0  0.0  15.0  9.0  23.0  10.0  2.0  2.0  24.0  1.0  4.0  0.0  2.0  1.0\n",
       "5  0.0  0.0  15.0  9.0  23.0  10.0  2.0  2.0  24.0  1.0  4.0  0.0  2.0  1.0\n",
       "6  0.0  0.0  15.0  9.0  23.0  10.0  2.0  2.0  24.0  1.0  4.0  0.0  2.0  1.0\n",
       "7  0.0  0.0  15.0  9.0  23.0  10.0  2.0  2.0  24.0  1.0  4.0  0.0  2.0  1.0\n",
       "8  1.0  1.0  11.0  8.0  10.0   5.0  3.0  0.0  11.0  1.0  4.0  2.0  2.0  0.0\n",
       "9  1.0  1.0  11.0  8.0  10.0   5.0  3.0  0.0  11.0  1.0  4.0  2.0  2.0  0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub_df = pd.read_csv('sub_data.csv', index_col=0)\n",
    "sub_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(1, 10):\n",
    "for i in range(1, 70905 + 10): # around 9 min\n",
    "    try:\n",
    "        row = test_db.get(i)\n",
    "        bonds = bondDistribution(row)\n",
    "\n",
    "        for bond in bonds:\n",
    "            if bond not in sub_df:\n",
    "                sub_df[bond] = 0\n",
    "            sub_df.loc[i, bond] = bonds[bond]\n",
    "\n",
    "        atoms = atomDistribution(row)\n",
    "        for atom in atoms:\n",
    "            if atom not in sub_df:\n",
    "                sub_df[atom] = 0\n",
    "            sub_df.loc[i, atom] = atoms[atom]\n",
    "    except:\n",
    "        print('stopped on', i)\n",
    "        break\n",
    "\n",
    "sub_df = sub_df.fillna(0)\n",
    "sub_df = sub_df.sort_index(axis=1)\n",
    "sub_df.to_csv('sub_data.csv')\n",
    "\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAWVgtIYbGT9"
   },
   "outputs": [],
   "source": [
    "sub_df_copy = pd.read_csv('/content/sub_data.csv', index_col=0)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in sub_df_copy and col != 'energy':\n",
    "        sub_df_copy[col] = 0\n",
    "\n",
    "sub_df_copy = sub_df_copy.sort_index(axis=1)\n",
    "\n",
    "sub_x = sub_df_copy.to_numpy()\n",
    "sub_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn_xm1gim-lP"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(sub_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui4iRy5poZWV"
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZqP67GqpjZR"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv', index_col = 'id')\n",
    "sub['energy'] = pred\n",
    "\n",
    "sub.to_csv('molecule_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl-PxatZkbQW"
   },
   "source": [
    "# GNN (не получилось)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soDqONSycDpb"
   },
   "source": [
    "## Preparing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wItmCoRjFMMq"
   },
   "outputs": [],
   "source": [
    "# input_shape  (batch, num_of_atoms, dims)\n",
    "# output_shape (batch, num_of_atoms, num_of_atoms)\n",
    "\n",
    "def get_distance_matrix(positionMatrix):\n",
    "    batch_size = positionMatrix.shape[0]\n",
    "    dims = positionMatrix.shape[2]\n",
    "\n",
    "    t1 = tf.reshape(positionMatrix, (batch_size, 1, -1, dims))\n",
    "    t2 = tf.reshape(positionMatrix, (batch_size, -1, 1, dims))\n",
    "    d = tf.norm(t1-t2, ord='euclidean', axis=3, keepdims=True)\n",
    "\n",
    "    return tf.squeeze(d, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_data(row):\n",
    "    p = row.positions \n",
    "    n = row.numbers.astype(\"float32\").reshape(1, -1, 1)\n",
    "    \n",
    "    # build not H-H bond matrix\n",
    "    h = row.symbols\n",
    "    h = (np.array(h) == 'H').astype(\"int\")[np.newaxis, ...]\n",
    "    nhh = 1 - h.T @ h\n",
    "    \n",
    "    dist_mat = get_distance_matrix(p[np.newaxis, ...])\n",
    "    adj_mat = tf.math.less(dist_mat, 7.)\n",
    "    adj_mat = tf.math.logical_and(adj_mat, nhh)\n",
    "    adj_mat = tf.cast(adj_mat, \"float32\")\n",
    "    \n",
    "    return n, adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes, adj_mat = get_graph_data(molecule)\n",
    "# deg = tf.reduce_sum(adj_mat, axis=-1)\n",
    "\n",
    "# print(deg.shape)     # (batch, num_of_atoms)\n",
    "# print(adj_mat.shape) # (batch, num_of_atoms, num_of_atoms)\n",
    "# print(nodes.shape)   # (batch, num_of_atoms, node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nodes[0])\n",
    "# # note to divide by degree, make the input 1 / degree\n",
    "# new_nodes = tf.einsum(\"bi,bij,bjk->bik\", 1 / deg, adj_mat, nodes)\n",
    "# print(new_nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZsZf4yfc9mG"
   },
   "source": [
    "## Graph NN Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XP7PBvPqdIgD"
   },
   "outputs": [],
   "source": [
    "# class GCNLayer(tf.keras.layers.Layer):\n",
    "#     \"\"\"Implementation of GCN as layer\"\"\"\n",
    "\n",
    "#     def __init__(self, activation=None, **kwargs):\n",
    "#         # constructor, which just calls super constructor\n",
    "#         # and turns requested activation into a callable function\n",
    "#         super(GCNLayer, self).__init__(**kwargs)\n",
    "#         self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         # create trainable weights\n",
    "#         node_shape, adj_shape = input_shape\n",
    "#         self.w = self.add_weight(shape=(node_shape[2], node_shape[2]), name=\"w\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # split input into nodes, adj\n",
    "#         nodes, adj = inputs\n",
    "#         # compute degree\n",
    "#         degree = tf.reduce_sum(adj, axis=-1)\n",
    "#         inf_degree = tf.math.less(degree, 1e-3)\n",
    "#         inf_degree = tf.cast(inf_degree, \"float32\") * 1e3\n",
    "#         # GCN equation\n",
    "#         new_nodes = tf.einsum(\n",
    "#             \"bi,bij,bjk,kl->bil\", \n",
    "#             tf.math.divide_no_nan(1., degree) + inf_degree, \n",
    "#             adj, \n",
    "#             nodes, \n",
    "#             self.w\n",
    "#         )\n",
    "#         out = self.activation(new_nodes)\n",
    "#         return out, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcnlayer = GCNLayer(\"relu\")\n",
    "# # we insert a batch axis here\n",
    "# gcnlayer((nodes, adj_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (nodes, adj_mat)\n",
    "# for i in range(2):\n",
    "#     x = gcnlayer(x)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRLayer(tf.keras.layers.Layer):\n",
    "#     \"\"\"A GNN layer that computes average over all node features\"\"\"\n",
    "\n",
    "#     def __init__(self, name=\"GRLayer\", **kwargs):\n",
    "#         super(GRLayer, self).__init__(name=name, **kwargs)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         nodes, adj = inputs\n",
    "#         reduction = tf.reduce_mean(nodes, axis=1)\n",
    "#         return reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITuCzCcjv-HE"
   },
   "source": [
    "## Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oro1-sZhv90N"
   },
   "outputs": [],
   "source": [
    "# ninput = tf.keras.Input(\n",
    "#     (\n",
    "#         None,  # num_of_atoms\n",
    "#         9,   # node_features\n",
    "#     )\n",
    "# )\n",
    "# ainput = tf.keras.Input(\n",
    "#     (\n",
    "#         None,  # num_of_atoms\n",
    "#         None,  # num_of_atoms\n",
    "#     )\n",
    "# )\n",
    "# # GCN block\n",
    "# x = GCNLayer(\"relu\")([ninput, ainput])\n",
    "# x = GCNLayer(\"relu\")(x)\n",
    "# x = GCNLayer(\"relu\")(x)\n",
    "# x = GCNLayer(\"relu\")(x)\n",
    "# # reduce to graph features\n",
    "# x = GRLayer()(x)\n",
    "# # standard layers (the readout)\n",
    "# x = tf.keras.layers.Dense(100, \"relu\")(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.Dense(100, \"relu\")(x)\n",
    "# x = tf.keras.layers.Dense(1)(x)\n",
    "# model = tf.keras.Model(inputs=(ninput, ainput), outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 17:09:25.824487: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 17:09:25.824723: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from spektral.layers.convolutional import gcn_conv\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "ninput = tf.keras.Input(\n",
    "    (\n",
    "        None,  # num_of_atoms\n",
    "        9,   # node_features\n",
    "    )\n",
    ")\n",
    "ainput = tf.keras.Input(\n",
    "    (\n",
    "        None,  # num_of_atoms\n",
    "        None,  # num_of_atoms\n",
    "    )\n",
    ")\n",
    "# GCN block\n",
    "x = gcn_conv.GCNConv(9, activation='relu')([ninput, ainput])\n",
    "x = Dropout(.5)(x)\n",
    "x = gcn_conv.GCNConv(9, activation='relu')([x, ainput])\n",
    "x = Dropout(.5)(x)\n",
    "x = gcn_conv.GCNConv(9, activation='relu')([x, ainput])\n",
    "x = Dropout(.5)(x)\n",
    "x = gcn_conv.GCNConv(9, activation='relu')([x, ainput])\n",
    "x = Dropout(.5)(x)\n",
    "x = gcn_conv.GCNConv(9, activation='relu')([x, ainput])\n",
    "x = Dropout(.5)(x)\n",
    "x = tf.reduce_mean(x, axis=1)\n",
    "x = Dense(16, \"relu\")(x)\n",
    "x = Dense(1)(x)\n",
    "model = tf.keras.Model(inputs=(ninput, ainput), outputs=x)\n",
    "model.compile(\"adam\", loss=\"mean_squared_error\", metrics=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Br, C, Cl,  F, H, N, O,  S, F\n",
    "35, 6, 17, 26, 1, 7, 8, 16, 9 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_map = {\n",
    "    0 : 0,\n",
    "    1 : 1, \n",
    "    6 : 2, \n",
    "    7 : 3, \n",
    "    8 : 4, \n",
    "    9 : 5, \n",
    "    16: 6, \n",
    "    17: 7, \n",
    "    26: 8, \n",
    "    35: 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZs_5s_-JPSV",
    "outputId": "def0bb52-96f1-4ca4-9570-00064eef3418"
   },
   "outputs": [],
   "source": [
    "def get_graph_data(numbers, positions):\n",
    "    n = np.array([[elements_map[el] for el in m] for m in numbers])\n",
    "    nodes = tf.one_hot(n, 9)\n",
    "    \n",
    "    # build not H-H bond matrix\n",
    "    h = (n == 0).astype(\"int\")\n",
    "    nhh = 1 - h.T @ h\n",
    "    \n",
    "    dist_mat = get_distance_matrix(positions)\n",
    "    adj_mat = tf.math.less(dist_mat, 7.)\n",
    "    adj_mat = tf.math.logical_and(adj_mat, nhh)\n",
    "    adj_mat = tf.cast(adj_mat, \"float32\")\n",
    "    \n",
    "    return nodes, adj_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(amount = 100000):\n",
    "    n = []\n",
    "    p = []\n",
    "    y = []\n",
    "\n",
    "    for row in train_db.select():\n",
    "        numbers = row.numbers\n",
    "        positions = row.positions\n",
    "        energy = row.data.get('energy')[0]\n",
    "        \n",
    "        n.append(np.pad(numbers, (0, 59 - len(numbers)) ))\n",
    "        p.append(np.pad(positions, ((0, 59 - len(numbers)), (0, 0)) ))\n",
    "        \n",
    "        y.append(energy)\n",
    "        if len(n) == amount:\n",
    "            break\n",
    "\n",
    "    n = np.array(n)\n",
    "    p = np.array(p)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(n.shape, p.shape, y.shape)\n",
    "\n",
    "    mask = n.reshape((-1, 1, 59))\n",
    "    mask = np.transpose(mask, (0, 2, 1)) @ mask\n",
    "    mask = 1 - np.equal(mask, 0)\n",
    "    # print(mask)\n",
    "\n",
    "    print(mask.shape)\n",
    "\n",
    "    train_n, train_adj_mat = get_graph_data(n, p)\n",
    "    train_adj_mat = train_adj_mat * mask\n",
    "    \n",
    "    print(train_adj_mat.shape)\n",
    "\n",
    "    return train_n, train_adj_mat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 59) (100000, 59, 3) (100000,)\n",
      "(100000, 59, 59)\n"
     ]
    }
   ],
   "source": [
    "train_n, train_adj_mat, y = get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxzTJSHzDWDA"
   },
   "source": [
    "## Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='log.csv'\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 80655.6016 - mean_absolute_error: 158.9618 - val_loss: 218294.4375 - val_mean_absolute_error: 308.5227\n",
      "Epoch 2/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 78679.3828 - mean_absolute_error: 157.0581 - val_loss: 206242.3281 - val_mean_absolute_error: 292.3441\n",
      "Epoch 3/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 76899.4688 - mean_absolute_error: 155.4019 - val_loss: 179785.3438 - val_mean_absolute_error: 274.9908\n",
      "Epoch 4/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 75860.0000 - mean_absolute_error: 154.4241 - val_loss: 166709.4219 - val_mean_absolute_error: 257.9569\n",
      "Epoch 5/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 74499.0703 - mean_absolute_error: 152.3529 - val_loss: 171109.1094 - val_mean_absolute_error: 252.6634\n",
      "Epoch 6/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 72255.2109 - mean_absolute_error: 152.5271 - val_loss: 141370.2812 - val_mean_absolute_error: 218.8054\n",
      "Epoch 7/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 72327.9062 - mean_absolute_error: 152.4512 - val_loss: 141082.0312 - val_mean_absolute_error: 220.0032\n",
      "Epoch 8/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 71514.6172 - mean_absolute_error: 152.1802 - val_loss: 138735.5781 - val_mean_absolute_error: 219.2379\n",
      "Epoch 9/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 71331.2188 - mean_absolute_error: 151.3831 - val_loss: 152427.7969 - val_mean_absolute_error: 236.0413\n",
      "Epoch 10/500\n",
      "792/792 [==============================] - 12s 16ms/step - loss: 70492.3516 - mean_absolute_error: 150.7274 - val_loss: 138814.2188 - val_mean_absolute_error: 221.4217\n",
      "Epoch 11/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 69058.7422 - mean_absolute_error: 149.9906 - val_loss: 112340.6016 - val_mean_absolute_error: 202.7079\n",
      "Epoch 12/500\n",
      "792/792 [==============================] - 13s 17ms/step - loss: 67646.3203 - mean_absolute_error: 150.0957 - val_loss: 108176.4062 - val_mean_absolute_error: 194.3287\n",
      "Epoch 13/500\n",
      "792/792 [==============================] - 14s 17ms/step - loss: 67099.8438 - mean_absolute_error: 149.6660 - val_loss: 106431.7578 - val_mean_absolute_error: 197.3745\n",
      "Epoch 14/500\n",
      "792/792 [==============================] - 14s 18ms/step - loss: 67382.6562 - mean_absolute_error: 149.5951 - val_loss: 111110.2188 - val_mean_absolute_error: 200.6346\n",
      "Epoch 15/500\n",
      "792/792 [==============================] - 15s 19ms/step - loss: 66491.0078 - mean_absolute_error: 148.7550 - val_loss: 120207.7188 - val_mean_absolute_error: 200.2377\n",
      "Epoch 16/500\n",
      "792/792 [==============================] - 15s 20ms/step - loss: 66499.1719 - mean_absolute_error: 149.2664 - val_loss: 113182.7031 - val_mean_absolute_error: 200.5531\n",
      "Epoch 17/500\n",
      "792/792 [==============================] - 16s 20ms/step - loss: 66144.2188 - mean_absolute_error: 148.0314 - val_loss: 117590.1172 - val_mean_absolute_error: 196.1605\n",
      "Epoch 18/500\n",
      "792/792 [==============================] - 16s 20ms/step - loss: 64937.4961 - mean_absolute_error: 147.5810 - val_loss: 100582.7031 - val_mean_absolute_error: 194.5444\n",
      "Epoch 19/500\n",
      "792/792 [==============================] - 16s 20ms/step - loss: 64619.1680 - mean_absolute_error: 147.5347 - val_loss: 94040.6953 - val_mean_absolute_error: 189.9365\n",
      "Epoch 20/500\n",
      "792/792 [==============================] - 16s 20ms/step - loss: 62254.9180 - mean_absolute_error: 146.8666 - val_loss: 79790.2344 - val_mean_absolute_error: 170.8996\n",
      "Epoch 21/500\n",
      "792/792 [==============================] - 16s 20ms/step - loss: 62118.5820 - mean_absolute_error: 146.3242 - val_loss: 77408.4844 - val_mean_absolute_error: 177.9995\n",
      "Epoch 22/500\n",
      "792/792 [==============================] - 2014s 3s/step - loss: 60133.0586 - mean_absolute_error: 145.2872 - val_loss: 79500.0859 - val_mean_absolute_error: 171.3858\n",
      "Epoch 23/500\n",
      "792/792 [==============================] - 1223s 2s/step - loss: 60372.3516 - mean_absolute_error: 145.5020 - val_loss: 80396.1016 - val_mean_absolute_error: 174.4601\n",
      "Epoch 24/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 58862.6289 - mean_absolute_error: 145.0914 - val_loss: 91790.6094 - val_mean_absolute_error: 186.3374\n",
      "Epoch 25/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 59512.2695 - mean_absolute_error: 144.9982 - val_loss: 67430.7812 - val_mean_absolute_error: 161.9654\n",
      "Epoch 26/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 58732.7500 - mean_absolute_error: 144.3995 - val_loss: 68796.4844 - val_mean_absolute_error: 169.1809\n",
      "Epoch 27/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 57682.9531 - mean_absolute_error: 143.6669 - val_loss: 64418.4727 - val_mean_absolute_error: 162.3885\n",
      "Epoch 28/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 56631.7969 - mean_absolute_error: 143.0108 - val_loss: 57841.2734 - val_mean_absolute_error: 158.9381\n",
      "Epoch 29/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 55440.0234 - mean_absolute_error: 141.7747 - val_loss: 55926.5469 - val_mean_absolute_error: 156.2233\n",
      "Epoch 30/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 54733.2500 - mean_absolute_error: 141.3109 - val_loss: 65701.8828 - val_mean_absolute_error: 161.4123\n",
      "Epoch 31/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 53693.8164 - mean_absolute_error: 140.8377 - val_loss: 51164.2930 - val_mean_absolute_error: 149.8540\n",
      "Epoch 32/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 51798.1953 - mean_absolute_error: 139.1495 - val_loss: 44229.4844 - val_mean_absolute_error: 145.3168\n",
      "Epoch 33/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 50988.6172 - mean_absolute_error: 138.2658 - val_loss: 48039.2305 - val_mean_absolute_error: 151.0573\n",
      "Epoch 34/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 50627.8281 - mean_absolute_error: 137.1421 - val_loss: 35380.0078 - val_mean_absolute_error: 130.6459\n",
      "Epoch 35/500\n",
      "792/792 [==============================] - 12s 15ms/step - loss: 49712.6445 - mean_absolute_error: 136.7556 - val_loss: 41055.7539 - val_mean_absolute_error: 140.5932\n",
      "Epoch 36/500\n",
      "792/792 [==============================] - 2045s 3s/step - loss: 47975.8750 - mean_absolute_error: 135.3132 - val_loss: 45876.1289 - val_mean_absolute_error: 140.1858\n",
      "Epoch 37/500\n",
      "792/792 [==============================] - 2039s 3s/step - loss: 47062.0977 - mean_absolute_error: 134.6043 - val_loss: 23780.2148 - val_mean_absolute_error: 115.3741\n",
      "Epoch 38/500\n",
      "792/792 [==============================] - 836s 1s/step - loss: 46988.5352 - mean_absolute_error: 133.6362 - val_loss: 33624.5117 - val_mean_absolute_error: 130.8810\n",
      "Epoch 39/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 44800.1602 - mean_absolute_error: 131.9623 - val_loss: 28140.5781 - val_mean_absolute_error: 121.2753\n",
      "Epoch 40/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 45233.3789 - mean_absolute_error: 131.5577 - val_loss: 29646.9531 - val_mean_absolute_error: 126.4489\n",
      "Epoch 41/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 43718.7383 - mean_absolute_error: 130.6593 - val_loss: 28221.8691 - val_mean_absolute_error: 127.9062\n",
      "Epoch 42/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 42771.6250 - mean_absolute_error: 129.6326 - val_loss: 19772.2168 - val_mean_absolute_error: 108.9158\n",
      "Epoch 43/500\n",
      "792/792 [==============================] - 13s 17ms/step - loss: 42795.9531 - mean_absolute_error: 129.4980 - val_loss: 24878.5020 - val_mean_absolute_error: 120.8460\n",
      "Epoch 44/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 41981.1719 - mean_absolute_error: 128.3424 - val_loss: 22479.5215 - val_mean_absolute_error: 114.5290\n",
      "Epoch 45/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 41871.9727 - mean_absolute_error: 128.2128 - val_loss: 22941.5664 - val_mean_absolute_error: 118.6839\n",
      "Epoch 46/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 41066.8047 - mean_absolute_error: 128.2758 - val_loss: 23983.0391 - val_mean_absolute_error: 117.1908\n",
      "Epoch 47/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 41190.9023 - mean_absolute_error: 127.6786 - val_loss: 20587.3125 - val_mean_absolute_error: 113.4901\n",
      "Epoch 48/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 40102.1992 - mean_absolute_error: 127.2763 - val_loss: 29185.3340 - val_mean_absolute_error: 127.5864\n",
      "Epoch 49/500\n",
      "792/792 [==============================] - 13s 16ms/step - loss: 39842.5117 - mean_absolute_error: 126.6259 - val_loss: 23521.6055 - val_mean_absolute_error: 117.1128\n",
      "Epoch 50/500\n",
      "456/792 [================>.............] - ETA: 5s - loss: 39434.6602 - mean_absolute_error: 126.1767"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adj_mat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhistory_logger\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_n, train_adj_mat], y,\n",
    "    validation_split = 0.01,\n",
    "    batch_size=125, epochs=500, verbose=1,\n",
    "    callbacks=[history_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\n",
    "#     \"./model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(filename)\n\u001b[1;32m      2\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      4\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "history = pd.read_csv(filename)\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(6, 8))\n",
    "\n",
    "ax1.plot(history[\"loss\"], label=\"training\")\n",
    "ax1.plot(history[\"val_loss\"], label=\"validation\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Model Loss (MSE)\")\n",
    "\n",
    "ax2.plot(history[\"mean_absolute_error\"], label=\"training\")\n",
    "ax2.plot(history[\"val_mean_absolute_error\"], label=\"validation\")\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Model MAE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "guDvrsppToQX",
    "aC89Bk8iPfym",
    "SZsZf4yfc9mG"
   ],
   "name": "rucode 5 (Molecule).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
